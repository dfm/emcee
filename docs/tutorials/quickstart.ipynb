{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(quickstart)=\n",
    "\n",
    "# Quickstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to get started with using emcee is to use it for a project. To get you started, here’s an annotated, fully-functional example that demonstrates a standard usage pattern.\n",
    "\n",
    "## How to sample a multi-dimensional Gaussian\n",
    "\n",
    "We’re going to demonstrate how you might draw samples from the multivariate Gaussian density given by:\n",
    "\n",
    "$$\n",
    "p(\\vec{x}) \\propto \\exp \\left [ - \\frac{1}{2} (\\vec{x} -\n",
    "    \\vec{\\mu})^\\mathrm{T} \\, \\Sigma ^{-1} \\, (\\vec{x} - \\vec{\\mu})\n",
    "    \\right ]\n",
    "$$\n",
    "\n",
    "where $\\vec{\\mu}$ is an $N$-dimensional vector position of the mean of the density and $\\Sigma$ is the square N-by-N covariance matrix.\n",
    "\n",
    "The first thing that we need to do is import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we’ll code up a Python function that returns the density $p(\\vec{x})$ for specific values of $\\vec{x}$, $\\vec{\\mu}$ and $\\Sigma^{-1}$. In fact, emcee actually requires the logarithm of $p$. We’ll call it `log_prob`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(x, mu, cov):\n",
    "    diff = x - mu\n",
    "    return -0.5 * np.dot(diff, np.linalg.solve(cov, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that the first argument of the probability function is\n",
    "the position of a single \"walker\" (a *N* dimensional\n",
    "`numpy` array). The following arguments are going to be constant every\n",
    "time the function is called and the values come from the `args` parameter\n",
    "of our {class}`EnsembleSampler` that we'll see soon.\n",
    "\n",
    "Now, we'll set up the specific values of those \"hyperparameters\" in 5\n",
    "dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 5\n",
    "\n",
    "np.random.seed(42)\n",
    "means = np.random.rand(ndim)\n",
    "\n",
    "cov = 0.5 - np.random.rand(ndim ** 2).reshape((ndim, ndim))\n",
    "cov = np.triu(cov)\n",
    "cov += cov.T - np.diag(cov.diagonal())\n",
    "cov = np.dot(cov, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and where `cov` is $\\Sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we use 32 walkers? Before we go on, we need to guess a starting point for each\n",
    "of the 32 walkers. This position will be a 5-dimensional vector so the\n",
    "initial guess should be a 32-by-5 array.\n",
    "It's not a very good guess but we'll just guess a\n",
    "random number between 0 and 1 for each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 32\n",
    "p0 = np.random.rand(nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten past all the bookkeeping stuff, we can move on to\n",
    "the fun stuff. The main interface provided by `emcee` is the\n",
    "{class}`EnsembleSampler` object so let's get ourselves one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[means, cov])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how our function `log_prob` required two extra arguments when it\n",
    "was called? By setting up our sampler with the `args` argument, we're\n",
    "saying that the probability function should be called as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob(p0[0], means, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we didn't provide any\n",
    "`args` parameter, the calling sequence would be `log_prob(p0[0])` instead.\n",
    "\n",
    "It's generally a good idea to run a few \"burn-in\" steps in your MCMC\n",
    "chain to let the walkers explore the parameter space a bit and get\n",
    "settled into the maximum of the density. We'll run a burn-in of 100\n",
    "steps (yep, I just made that number up... it's hard to really know\n",
    "how many steps of burn-in you'll need before you start) starting from\n",
    "our initial guess ``p0``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = sampler.run_mcmc(p0, 100)\n",
    "sampler.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that I saved the final position of the walkers (after the\n",
    "100 steps) to a variable called `state`. You can check out what will be\n",
    "contained in the other output variables by looking at the documentation for\n",
    "the {func}`EnsembleSampler.run_mcmc` function. The call to the\n",
    "{func}`EnsembleSampler.reset` method clears all of the important bookkeeping\n",
    "parameters in the sampler so that we get a fresh start. It also clears the\n",
    "current positions of the walkers so it's a good thing that we saved them\n",
    "first.\n",
    "\n",
    "Now, we can do our production run of 10000 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run_mcmc(state, 10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples can be accessed using the {func}`EnsembleSampler.get_chain` method.\n",
    "This will return an array\n",
    "with the shape `(10000, 32, 5)` giving the parameter values for each walker\n",
    "at each step in the chain.\n",
    "Take note of that shape and make sure that you know where each of those numbers come from.\n",
    "You can make histograms of these samples to get an estimate of the density that you were sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples = sampler.get_chain(flat=True)\n",
    "plt.hist(samples[:, 0], 100, color=\"k\", histtype=\"step\")\n",
    "plt.xlabel(r\"$\\theta_1$\")\n",
    "plt.ylabel(r\"$p(\\theta_1)$\")\n",
    "plt.gca().set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good test of whether or not the sampling went well is to check\n",
    "the mean acceptance fraction of the ensemble using the\n",
    "{func}`EnsembleSampler.acceptance_fraction` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the integrated autocorrelation time (see the {ref}`autocorr` tutorial for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean autocorrelation time: {0:.3f} steps\".format(\n",
    "        np.mean(sampler.get_autocorr_time())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
